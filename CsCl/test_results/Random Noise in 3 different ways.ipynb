{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Random Noise to Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "from numpy.fft import fftn, fftshift # no need to use numpy.fft.fftn/fftshift\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as pypl\n",
    "import os, time\n",
    "this_dir = os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Boolean Expression to Chooose which Parts to Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Choose What to Run: ----\n",
    "random_noise_1quad =True\t\t\t## Generate random Noise in one quardant ##\n",
    "\n",
    "plot_diffraction = False\t\t## if False : No plot of Diffractin Patterns ##\n",
    "XCCA_Loki = True \t\t\t\t## if True: run XCCA with Loki-pkg ##\n",
    "XCCA_cxiLT14py = True\t## if True: run XCCA with A.Martins Scripts ##\n",
    "\n",
    "add_noise = True\t\t\t\t\t\t## Add Generated Noise to Correlations ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Diffraction Patterns e.g. for 'noisefree_Beam-NarrInt_84-119_4M0_ed_(none-sprd0)_#5.cxi' (GDrive/experiments/LCLS/CXI-2018_Martin/simulations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name ='noisefree_Beam-NarrInt'\n",
    "run = '84-119'\n",
    "pdb = '4M0_ed'\n",
    "noisy = 'none'\n",
    "n_spread= 0\n",
    "N= 5\n",
    "\n",
    "rmin, rmax = 300, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----\tRead in Data from CXI-file: ----\n",
    "if N is None:\tdata_file =sim_res_dir+'/%s_%s_%s_(%s-sprd%s).cxi'%(name,run,pdb,noisy,n_spread)\n",
    "else:\tdata_file =sim_res_dir +'/%s_%s_%s_(%s-sprd%s)_#%i.cxi'%(name,run,pdb,noisy,n_spread,N)\n",
    "\n",
    "with h5py.File(data_file, 'r') as f:\n",
    "\tintensity_pattern = np.asarray(f[\"entry_1/data_1/data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 'Better Mask Assembled':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\t--- Mask from assembly (only 0.0 an 1.0 in data): ---\n",
    "mask_better = np.load(\"%s/masks/better_mask-assembled.npy\" %str(this_dir))\n",
    "## if data is not NOT binary:  ione =np.where(mask_better < 1.0), mask_better[ione] = 0.0 # Make sure that all data < 1.0 is 0.0 \t##  \n",
    "mask_better = mask_better.astype(int) \t## Convert float to integer ##\n",
    "print\"Dim of the assembled mask: \", mask_better.shape\n",
    "\n",
    "Ip_w_mb=np.multiply(intensity_pattern,mask_better)\t# Intensity Pattern with Mask\n",
    "#Ap_w_mb=np.multiply(amplitudes_pattern,mask_better) # Amplitude Pattern (Complex) with Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Center from the loaded Mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Centre Coordiates : ----\n",
    "cntr_msk =np.asarray([(mask_better.shape[1]-1)/2.0, (mask_better.shape[0]-1)/2.0 ]) ## (X,Y)\n",
    "print \"\\n Centre from Mask: \", cntr_msk ##[870, 868]; [869.5, 871.5]; [871.5, 869.5]\n",
    "cntr= cntr_msk \t## (X,Y) if use center point from the Msak ##\n",
    "cntr_int=np.around(cntr).astype(int)  ## (rounds to nearest int) for the center coordinates in pixles as integers ##\n",
    "print \"\\n Centre as Integer: \", cntr_int,  \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try 3 Different Ways to add Noise to the 2nd quadrant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = intensity_pattern\n",
    "nlevel = 0.2\t## highest level of noise in percent of Maximum signal ##\n",
    "\n",
    "# ---- Noise Matrices (Y, X) : ---- #\n",
    "rand_1quad_b1 = np.ones_like(ip,dtype=float)\t## noise-free = 1 ##\n",
    "rand_1quad_b0 = np.zeros(ip.shape, dtype=float) ## noise-free = 0 ##\n",
    "\n",
    "#---- Noise reduce the signal pxl-by-pxl by 0-nlevel % : ---- #\n",
    "inv_nlevel = np.around(1.0-nlevel, 1) ## since in python 1.0-0.8=0.19999999999999996 ##\n",
    "\n",
    "## Max 20 % of the signal is retained (min of 20% noise): ##\n",
    "rand_b1_max = rand_1quad_b1 \n",
    "## Min 20 % of the signal is retained (max of 20% noise): ##\n",
    "rand_b1_min =rand_1quad_b1 \n",
    "\n",
    "for idx in range(intensity_pattern.shape[0]):\n",
    "    ## rand(n,m) yield nxm of numbers (0.0,1.0) ##\n",
    "    ## Max 80 % of the signal is retained (min of 20% noise): random-numbers*80% ##\n",
    "    rand_b1_max[idx][:cntr_int[1],:cntr_int[0]] =  np.random.rand(cntr_int[1], cntr_int[0])*inv_nlevel\n",
    "    ## Min 80 % of the signal is retained (max of 20% noise): 1-random-numbers*20%##\n",
    "\trand_b1_min[idx][:cntr_int[1],:cntr_int[0]] =  1.0-np.random.rand(cntr_int[1], cntr_int[0])*nlevel\n",
    "\n",
    "#---- Add the Noise to the Intensity Patterns : ---- #\n",
    "img_w_rand_noise_b1_mx = (ip*rand_b1_max)\n",
    "img_w_rand_noise_b1_mn = (ip*rand_b1_min)\n",
    "#print \"Dim of 'img_w_rand_noise_b1_mx': \", img_w_rand_noise_b1_mx.shape ## = (5, 1738, 1742) ##\n",
    "\n",
    "#---- Add the Mask to the partially Noisy Intensity Patterns : ---- #\n",
    "img_w_rand_noise_b1_mx= np.multiply(img_w_rand_noise_b1_mx,mask_better)\n",
    "img_w_rand_noise_b1_mn= np.multiply(img_w_rand_noise_b1_mn,mask_better)\n",
    "print \"\\n ... imgs for b1 min & max generated!\"\n",
    "\n",
    " \n",
    "#---- Noise 0-'nlevel'% of max signal in quadrant of 1st Pattern (avoid centre max from simulation box): ---- #\n",
    "for idx in range(intensity_pattern.shape[0]):\n",
    "\t## rand(n,m) yield nxm of numbers (0.0,1.0); raindint(low,high) ##\n",
    "\trand_1quad_b0[idx][:cntr_int[1],:cntr_int[0]] = np.random.rand(cntr_int[1], cntr_int[0])*ip[idx][:cntr_int[1]-250,:cntr_int[0]-250].max()*nlevel\n",
    "\t# img_w_rand_noise_b0[idx] = (ip[idx]-rand_1quad_b0[idx])\n",
    "img_w_rand_noise_b0 = (ip-rand_1quad_b0)\n",
    "img_w_rand_noise_b0= np.multiply(img_w_rand_noise_b0,mask_better)\n",
    "#print \"Dim of 'img_w_rand_noise_b0 ': \",img_w_rand_noise_b0.shape  ## = (5, 1738, 1742) ##\n",
    "print \"\\n ... img for b0 generated!\"\n",
    "\n",
    "\n",
    "if add_noise:  ## Choose Which Noise Profile to use in CCA ##\n",
    "\t## img_w_rand_noise_b1_mx;  img_w_rand_noise_b1_mn ; img_w_rand_noise_b0 \n",
    "\tIp_w_mb_w_Ns = img_w_rand_noise_b1_mx\n",
    "\t#Ip_w_mb_w_Ns = img_w_rand_noise_b1_mn\n",
    "\t#Ip_w_mb_w_Ns = img_w_rand_noise_b0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 3 Different Noise-Maps and their Resulting Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_noise = pypl.figure('noise', figsize=(12,10)) ## R1: Noise Maps; R2: Patterns ##\n",
    "indx = 2 \t## Which pattern to Plot ## \n",
    "\n",
    "vmax = max(np.amax(img_w_rand_noise_b1_mx), np.amax(img_w_rand_noise_b0)) ## max from rand-noise ##\n",
    "print \"max value in paterns: \", vmax\n",
    "\n",
    "## PLOT of Max 80 % of the signal is retained (min of 20% noise): ##\n",
    "pypl.subplot(231)\n",
    "pypl.imshow(rand_b1_max[indx], cmap='viridis')\n",
    "pypl.title('Noise Map of max %i %% of signal retained \\n' %(inv_nlevel*100), fontsize=12)\n",
    "pypl.colorbar( shrink=0.7) #pypl.colorbar(orientation=\"horizontal\")\n",
    "pypl.subplot(234)\n",
    "img_b1_mx = np.ma.masked_where(mask_better == 0, img_w_rand_noise_b1_mx[indx])\n",
    "pypl.imshow(img_b1_mx, vmin=0.1, vmax=vmax, cmap='viridis')\n",
    "pypl.title('Noise: max %i %% of signal retained \\n' %(inv_nlevel*100), fontsize=12)\n",
    "cmap = cm.viridis\n",
    "cmap.set_bad('grey',1.)\n",
    "cmap.set_under('white',1.) \n",
    "\n",
    "## PLOT of Min 80 % of the signal is retained (max of 20% noise): ##\n",
    "pypl.subplot(232)\n",
    "pypl.imshow(rand_b1_min[indx], cmap='viridis')\n",
    "pypl.title('Noise Map of min %i %% of signal retained \\n' %(inv_nlevel*100), fontsize=12)\n",
    "pypl.colorbar( shrink=0.7)\n",
    "pypl.subplot(235)\n",
    "img_b1_mn = np.ma.masked_where(mask_better == 0, img_w_rand_noise_b1_mn[indx])\n",
    "pypl.imshow(img_b1_mn, vmin=0.1, vmax=vmax, cmap='viridis')\n",
    "pypl.title('Noise: min %i %% of signal retained \\n' %(inv_nlevel*100), fontsize=12)\n",
    "cmap = cm.viridis\n",
    "cmap.set_bad('grey',1.)\n",
    "cmap.set_under('white',1.)\n",
    "\n",
    "\n",
    "## PLOT of Noise prop to max signal of 1st Pattern : ##\n",
    "pypl.subplot(233)\n",
    "pypl.imshow(rand_1quad_b0[indx], cmap='viridis')\n",
    "pypl.title('Noise Map of max %i %% of Signal Maximum \\n' %(nlevel*100), fontsize=12)\n",
    "pypl.colorbar( shrink=0.7)\n",
    "pypl.subplot(236)\n",
    "img_b0 = np.ma.masked_where(mask_better == 0, img_w_rand_noise_b0[indx])\n",
    "pypl.imshow(img_b0, vmin=0.1, vmax=vmax, cmap='viridis')\n",
    "pypl.title('Noise: max %i %% of Signal Maximum \\n' %(nlevel*100), fontsize=12)\n",
    "cmap = cm.viridis\n",
    "cmap.set_bad('grey',1.)\n",
    "cmap.set_under('white',1.)\n",
    "\n",
    "cax = pypl.axes([0.065, 0.03, 0.88, 0.04])  ## left, bottom, width, hight ##\n",
    "pypl.colorbar(cax=cax, orientation='horizontal')\n",
    "\n",
    "pypl.suptitle(\"Random Noise in 2nd quadrant of Pattern No.%i\" %(indx+1), fontsize=16)\n",
    "pypl.subplots_adjust(wspace=0.4, hspace=0.4, left=0.07, right=0.95)\n",
    "pic_name = '%s_%s_(%s-%s)_subplot_of_Random_Noise_1st-quad_Pattern-%i_(%iprc).%s'%(name,pdb,noisy,n_spread,(indx+1),nlevel*100,frmt)\n",
    "#pypl.savefig(outdir + pic_name)\n",
    "print \"Plot saved in %s \\n as %s\" %(outdir, pic_name)\n",
    "pypl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CCA with LOKI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing & Creating Storage Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XCCA_Loki:\n",
    "\tfrom loki import RingData \t## RingData is a folder\n",
    "\tprint \"\\n Data Analysis with LOKI.\\n\"\n",
    "    from pylab import *\t# load all Pylab & Numpy\n",
    "\tfrom loki.RingData import DiffCorr, InterpSimple\n",
    "\tprint \"\\n Start Running 'Centre of Detector Loaded From File'.\\n\"\n",
    "    \n",
    "    m_b = mask_better\n",
    "    img = Ip_w_mb\n",
    "    pttrn = \"Int\"\n",
    "    if add_noise:\n",
    "\t\timg = Ip_w_mb_w_Ns\n",
    "\t\tpttrn = \"Int-add-noise-%iprc\" %(nlevel*100)\n",
    "\n",
    "    \n",
    "    # ---- Generate a Storage File's Prefix: ---- \n",
    "\tif random_noise_1quad:\n",
    "\toutdir = this_dir + '/random_noise_1quad_(%s_%s_%s)/' %(pdb,noisy,n_spread)\n",
    "    else: outdir=this_dir\n",
    "\tif not os.path.exists(outdir):\n",
    "\t\tos.makedirs(outdir)\n",
    "\tprefix = '%s_%s_' %(name,pdb)\n",
    "\tloki_folder = outdir + '/%s_%s_%s_with_LOKI/' %(name,run,pdb)\n",
    "\tif not os.path.exists(loki_folder):\n",
    "\t\tos.makedirs(loki_folder)\n",
    "\tout_fname = os.path.join( loki_folder, prefix)\n",
    "    \n",
    "    if N == 1: calc_AutoCorr = False\t## Auto-correlation between diff. diffraction Patterns ##\n",
    "\telse:  calc_AutoCorr = True \t\t## only for N > 1 (ense no pattern to compare to) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters for CCA & Polar Calculasions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    qmin_pix = rmin\n",
    "\tqmax_pix = rmax\n",
    "\n",
    "\t# ---- Single Pixel Resolution at Maximum q [1/A]: -----\n",
    "\tnphi = 180#360#180##90#\n",
    "\tprint \"\\n nphi: \", nphi \t# = ,  20 (qmx=1135),  5(qmx=250)\n",
    "\n",
    "\t# ----- nphi (ANGULAR) Tic Parameters for choosen Pixel Resolution (for PLOTTING): ----\n",
    "\tnphi_bins = [nphi/8.0, nphi/4.0, nphi/2.0, 3*nphi/4.0, 7*nphi/8.0]\t# \t# [nphi/4, nphi/2, 3*nphi/4]\n",
    "\tnphi_label = [r\"$\\pi/4$\", r\"$\\pi/2$\", r\"$\\pi$\", r\"$3\\pi/2$\", r\"$7\\pi/4$\" ]\t# center of columen for full Period 2pi, # [ r'$\\pi/2$', r'$\\pi$', r'$3\\pi/2$']\n",
    "\n",
    "\t# ---- Save g-Mapping (the q- values [qmin_pix,qmin_pix]): ----\n",
    "\tg_diff = qmax_pix -qmin_pix\n",
    "\tqrange_pix = np.arange( qmin_pix, qmax_pix)\n",
    "\tq_map = np.array( [ [ind, pix2invang(q)] for ind,q in enumerate( qrange_pix)])\n",
    "\n",
    "\t# ----- q (RADIAL) Tic Parameters for choosen Pixel Resolution (for PLOTTING): ----\n",
    "\tnq = q_map.shape[0]#q_step \t# Number of q radial polar bins\n",
    "\tq_bins = arange( 0, nq, nq/10 )\t# 6 ticks arrange(start, stop, step-size)\n",
    "\tq_label = [ '%.3f'%(q_map[x,1]) for x in q_bins]\n",
    "\n",
    "\t# ---- Interpolater initiate : ----\t# fs = fast-scan {x} cntr[0]; Define a polar image with dimensions: (qRmax-qRmin) x nphi\n",
    "\tInterp = RingData.InterpSimple( cntr[0], cntr[1], qmax_pix, qmin_pix, nphi, m_b.shape)\n",
    "\n",
    "\t# ---- Make a Polar Mask : ----\n",
    "\tpolar_mask = Interp.nearest(m_b, dtype=bool).round() ## .round() returns a floating point number that is a rounded version of the specified number ##\n",
    "\n",
    "\t# ---- Generate Polar Image/Images (N Diffracton Patterns) : ----\n",
    "\tprint \"\\n Starting to Calculate the Polar Images...\\n\"\n",
    "\tpolar_imgs = np.array( [ polar_mask* Interp.nearest(img[i]) for i in range( N) ] )\n",
    "\n",
    "\t# ---- Normalize - with function: ----\n",
    "\t#polar_imgs_norm =norm_polar_img(polar_imgs, mask_val=0) # Function\n",
    "\t## alt try: polar_imgs_norm = norm_data(polar_imgs)\n",
    "\tpolar_imgs_norm = polar_imgs ## skip normalisation of simulated data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Diffractions with Each Other (AUTO-Correlation) for N Patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t#from Loki/Salca CXS tutorial\n",
    "\tif calc_AutoCorr:\n",
    "\t\tt_AC = time.time()\n",
    "\t\tprint \"\\n Starting to Auto-Correlate the Polar Images...\\n\"\n",
    "\t\t# ---- Calculate the Difference in Intensities and store in a List: ----\n",
    "\t\texposure_diffs = []\n",
    "\t\texposure_diffs_cart =img[:-1]-img[1:]\t\t\t\t# Intensity Patterns in Carteesian cor\n",
    "\t\timg_mean = np.array([ img[i].mean() for i in range(img.shape[0]) ]) ## Calculate the Mean of each pattern(shot) ##\n",
    "\t\t#exposure_diffs_cart= img[:-1]/img_mean[:-1]-img[1:]/img_mean[1:]  ## Normalize each pattern(shot) before subtraction ##\n",
    "\t\tdel img_mean \t## Do not need the mean-values anymore ##\n",
    "\t\texposure_diffs_cart = np.asarray(exposure_diffs_cart) \t# = (4, 1738, 1742)\n",
    "\t\texposure_diffs_cart = polarize(exposure_diffs_cart)  ## Polarize (if no fraction given => just 1s) ##\n",
    "\t\texposure_diffs_cart = np.array( [ polar_mask* Interp.nearest(exposure_diffs_cart[i]) for i in range(exposure_diffs_cart.shape[0]) ] ) ## conv to polar of diff-data ##\n",
    "\t\t\n",
    "\t\texposure_diffs_pol =polar_imgs_norm[:-1]-polar_imgs_norm[1:]\t# Polar Imgs\n",
    "\t\texposure_diffs_pol = np.asarray(exposure_diffs_pol) \t# = (4, 190, 5)\n",
    "\n",
    "\t\t# ---- Autocorrelation of each Pair: ----\n",
    "\t\tacorr = [RingData.DiffCorr( exposure_diffs_cart).autocorr(), \n",
    "\t\t\t\t\t\tRingData.DiffCorr( exposure_diffs_pol ).autocorr()]\n",
    "\t\tcor_mean = [RingData.DiffCorr( exposure_diffs_cart).autocorr().mean(0), \n",
    "\t\t\t\t\t\tRingData.DiffCorr( exposure_diffs_pol ).autocorr().mean(0)]\n",
    "\n",
    "\t\t# ---- Choose in which coordinate Systam to plot Autocorrelation in: ----\t\t\t\t\n",
    "\t\tpolar_diff = True#False\n",
    "\t\tif not polar_diff: \t# In Carteesian Coordinate System\n",
    "\t\t\tind =0\n",
    "\t\t\tcord_sys = \"Carteesian-diff\"\n",
    "\t\telse:\t\t\t# In Polar Coordinate System\n",
    "\t\t\tind = 1\n",
    "\t\t\tcord_sys = \"Polar-diff\"\n",
    "\t\tcor_mean = np.asarray(cor_mean[ind]) # 0 = cart; 1 = polar\n",
    "\n",
    "\t\tt = time.time()-t_AC\n",
    "\t\tt_m =int(t)/60\n",
    "\t\tt_s=t-t_m*60\n",
    "\t\tprint \"AutoCorrelation Time: \", t_m, \"min, \", t_s, \" s \\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Auto-Correlations with the Random Noise in the 2nd quadrant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t######################  PLOT Auto-Correlations [fig.4] : ################################################################## \n",
    "\t\tpypl.figure(4, figsize=(18,10))\n",
    "\t\tcb_shrink, cb_padd = 1.0, 0.2\n",
    "\t\tpypl.subplot(121) #ALT. figure(figsize = (10, 10))\n",
    "\t\tim=imshow ( cor_mean, aspect='auto')\n",
    "        cb = pypl.colorbar(im, orientation=\"horizontal\", shrink=cb_shrink, pad= cb_padd, format = '%8.1e')\t\n",
    "\t\tcb.set_label(r'Auto-correlation of Intensity Difference [a.u.]',  size=12) # normed intensity\n",
    "\n",
    "\t\tif polar_diff:\n",
    "\t\t\t# #---- Adjust the X-axis: ----  \t\t## NEED Adj x tic for 5 tics\n",
    "\t\t\txtic = nphi_bins \t#[nphi/4, nphi/2, 3*nphi/4]\n",
    "\t\t\txlab = nphi_label \t\t\t# [ r'$\\pi/2$', r'$\\pi$', r'$3\\pi/2$'] #nphi_bins or phi_bins_5\n",
    "\t\t\tpypl.xticks(xtic, xlab)\n",
    "\n",
    "\t\t\t# #---- Adjust the Y-axis: ----\n",
    "\t\t\tytic = q_bins # arange( 0, nq, nq/10 )\t# 6 ticks arrange(start, stop, step-size)\n",
    "\t\t\tylab = q_label # [ '%.3f'%(q_map[x,1]) for x in ytic]\n",
    "\t\t\tpypl.yticks(ytic, ylab)\n",
    "\n",
    "\t\t\t# #---- Label xy-Axis: ----\n",
    "\t\t\tpypl.xlabel(r'$\\phi$', fontsize = 18)\n",
    "\t\t\tpypl.ylabel(r'$q \\, [\\AA^{-1}]$', fontsize =18)\n",
    "\n",
    "\t\tpypl.title(\"Auto-Correlation [%s] of %i patterns\" %(cord_sys,N),  fontsize=16)\n",
    "\t\t############### [fig.4b]  Plot Sigma (Normed Auto-Correlation with +-2 std as limits)  ##############\n",
    "\t\tsubplt_ave_corrs = True#False \t\t#### Plot the 2nd plot {adapted from in // GDrive/.../scripts/ave_corrs & 'plot_a_corr.py'} ####\n",
    "\t\tif subplt_ave_corrs:\n",
    "\t\t\tpypl.subplot(122) \t#### plot as in // GDrive/.../scripts/ave_corrs & 'plot_a_corr.py' #####\n",
    "\t\t\tcorr = None\n",
    "\t\t\tfor i in range(acorr[ind].shape[0]):\t\t#acorr[ind].shape = (4, 190, 5)\n",
    "\t\t\t\tif corr is None:\tcorr = acorr[ind][i]\n",
    "\t\t\t\telse :\tcorr += acorr[ind][i]\t\t# adter loop cr.shape = (190, 5)\n",
    "\t\t\t#print \"\\n corr shape: \", acorr[ind].shape, \"\\n & corr : \", corr.shape\n",
    "\t\t\tcorrsum = np.zeros_like(corr)\t\t\n",
    "\t\t\tcorr_count =np.zeros(1)+(exposure_diffs_pol.shape[0]) #exposure_diffs_pol.shape[0] = N-1\n",
    "\t\t\t#print \"corr_count: \", corr_count\n",
    "\t\t\t#test = np.zeros(1)\n",
    "\t\t\t#test += 4\n",
    "\t\t\t#print \"np.zeroes(1) \", np.zeros(1), \" \\n and add 1 to array: \", test, \"\\n\"\n",
    "\t\t\ttot_corr_count = np.zeros(1)\n",
    "\t\t\t#print \"\\n tot_corr_count: \", tot_corr_count\n",
    "\t\t\tfrom mpi4py import MPI\n",
    "\t\t\tcomm = MPI.COMM_WORLD\n",
    "\t\t\tcomm.Reduce(corr,corrsum)\n",
    "\t\t\tcomm.Reduce(corr_count, tot_corr_count)\n",
    "\n",
    "\t\t\tcorrsum  =np.nan_to_num(corrsum)\n",
    "\t\t\tsig = corrsum/corrsum[:,0][:,None]/tot_corr_count[0] #if Polar: RuntimeWarning: invalid value encountered in divide ###### !ERROR !!!\n",
    "\t\t\tsig  =np.nan_to_num(sig)\n",
    "\n",
    "            padC = 10#50 \t# pad the edges of the correlation (remove self-correlation junk) /l.181\n",
    "\t\t\tm = sig[:,padC:-padC].mean() \t# MEAN\n",
    "\t\t\ts = sig[:,padC:-padC].std() \t# standard Deeviation\n",
    "\t\t\tvmin = m-2*s\n",
    "\t\t\tvmax = m+2*s\n",
    "\t\t\t\n",
    "\t\t\tax = pypl.gca()\n",
    "\t\t\tif polar_diff:\n",
    "\t\t\t\tim = ax.imshow( sig,\n",
    "          \t            extent=[0, 2*np.pi, qmax_pix, qmin_pix], \n",
    "           \t            vmin=vmin, vmax=vmax, aspect='auto')\n",
    "\t\t\telse : im =ax.imshow(sig, vmin=vmin, vmax=vmax, aspect='auto' )\n",
    "\t\t\tcb = pypl.colorbar(im, orientation=\"horizontal\", shrink=cb_shrink, pad= cb_padd)\t\n",
    "\t\t\tcb.set_label(r'Auto-correlation of Intensity Difference [a.u.]',  size=12) # normed intensity\n",
    "\t\t\tax.set_title(r\"Average of %d corrs [%s] with limits $\\mu \\pm 2\\sigma$\"%(tot_corr_count[0], cord_sys),  fontsize=16)\n",
    "\t\t\t############### [fig.4b] End ###############\n",
    "\t\t#pypl.rcParams.update({'axes.labelsize': 14, 'xtick.labelsize':'small', 'ytick.labelsize':'small'})\n",
    "\t\tpypl.subplots_adjust(wspace=0.2, hspace=0.2, left=0.07, right=0.99)\n",
    "\t\tfig_name = \"Figure_4_Diff-Auto-Corr_SUBPLOT_(qx-%i_qi-%i_nphi-%i)_w_Mask_%s_%s.%s\" %(qmax_pix,qmin_pix, nphi,cord_sys,pttrn,frmt)\n",
    "\t\t#pypl.savefig( out_fname + fig_name)\n",
    "\t\tprint \"\\n Sub-plot saved as %s \" %fig_name\n",
    "        pypl.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
